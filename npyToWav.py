import os
import sys

import json
import torch
import numpy as np
import soundfile as sf

# ê²½ë¡œ ì„¤ì • (ë³€ê²½ ë°˜ì˜ë¨)
mel_path = "/Users/simjuheun/Desktop/myProject/Use_Magenta/MIDItowave/test/0ec264d4f0b5938d9d074e4b252e9d5e.npy"
checkpoint_path = "/hifi_gan_Chords/hifi-gan/universal/g_02500000"
config_path = "/hifi_gan_Chords/hifi-gan/universal/config.json"
output_path = "/hifi_gan_Chords/audioResult/0ec264d4f0b5938d9d074e4b252e9d5e_generated.wav"

# sys.path ì¶”ê°€ (ëª¨ë¸ ì„í¬íŠ¸ë¥¼ ìœ„í•œ ê²½ë¡œ)
sys.path.append("/hifi_gan_Chords/hifi-gan")
from models import Generator


# AttrDict
class AttrDict(dict):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.__dict__ = self


# Config ë¡œë“œ
with open(config_path) as f:
    config = AttrDict(json.load(f))

# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ëª¨ë¸ ë¡œë“œ
model = Generator(config).to(device)
checkpoint = torch.load(checkpoint_path, map_location=device)
model.load_state_dict(checkpoint["generator"])
model.eval()
model.remove_weight_norm()
print("âœ… Generator ë¡œë“œ ì™„ë£Œ")

# mel ë¡œë“œ + í‰ê·  ì—ë„ˆì§€ ì •ê·œí™”
mel = np.load(mel_path)
mean_energy = np.mean(mel)
if mean_energy < 1.0:
    scale_factor = 1.0 / (mean_energy + 1e-6)
    mel *= scale_factor
    print(f"ğŸ”§ í‰ê·  ì—ë„ˆì§€ ë‚®ìŒ â†’ ìŠ¤ì¼€ì¼ ë³´ì • ì ìš©: x{scale_factor:.2f}")

# ì¶”ë¡ 
mel_tensor = torch.FloatTensor(mel).unsqueeze(0).to(device)
with torch.no_grad():
    audio = model(mel_tensor).squeeze().cpu().numpy()

# ì •ê·œí™” í›„ ì €ì¥
audio = audio / np.max(np.abs(audio))
sf.write(output_path, audio, config.sampling_rate)

print(f"ğŸ§ ì˜¤ë””ì˜¤ ì €ì¥ ì™„ë£Œ: {output_path}")
print(f"ğŸ” MEL shape: {mel.shape} | mean: {mel.mean():.4f}, min: {mel.min():.4f}, max: {mel.max():.4f}")
print(f"ğŸ”Š Audio stats â†’ shape: {audio.shape}, min: {audio.min():.4f}, max: {audio.max():.4f}, mean: {audio.mean():.4f}")