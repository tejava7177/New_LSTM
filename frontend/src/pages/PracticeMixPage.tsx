import { useEffect, useMemo, useRef, useState } from 'react'
import { useLocation } from 'react-router-dom'
import DeviceSelect from '../components/DeviceSelect'
import { useMediaRecorder } from '../hooks/useMediaRecorder'
import { audioBufferToWavBlob } from '../utils/wav'
import { mixBuffersToAudioBuffer } from '../lib/mixdown'
import { Midi } from '@tonejs/midi'
import { renderMidiOnServer } from '../lib/midiServer'
import { midiUrl, wavUrl } from '../lib/tracks'
import { extractChordCuesFromMidi, getNowNextChord, ChordCue } from '../lib/midiCues'

type TrackMeta = { name: string; channel?: number; instrument?: string; notes: number }
type NavState = {
  source?: 'predict' | 'manual';
  jobId?: string;
  progression?: string[];
  tempo?: number;
  timeSig?: [number, number];
  preRollBeats?: number;
  barsPerChord?: number;
  midiUrl?: string; // optional override
  wavUrl?: string;  // optional override
}

export default function PracticeMixPage() {
  /* ===== ë¼ìš°í„° state ===== */
  const { state } = useLocation()
  const navState = (state as NavState) || {}

  /* ===== ì…ë ¥ & ë…¹ìŒ ===== */
  const [deviceId, setDeviceId] = useState<string>('')
  const { recording, blobUrl, start, stop, error: recErr } = useMediaRecorder(deviceId || undefined)

  /* ===== MIDI ë¡œë”© & ë Œë”ë§ ===== */
  const [midiFile, setMidiFile] = useState<File | null>(null)
  const [midiAudioUrl, setMidiAudioUrl] = useState<string | null>(null)
  const [midiBuffer, setMidiBuffer] = useState<AudioBuffer | null>(null)
  const [midiTracks, setMidiTracks] = useState<TrackMeta[]>([])
  const [rendering, setRendering] = useState(false)

  /* ë©”íƒ€ */
  const [tempoBpm, setTempoBpm] = useState<number>(navState.tempo ?? 100)
  const [timeSig, setTimeSig] = useState<[number, number]>(navState.timeSig ?? [4, 4])

  /* ì½”ë“œ í (ë§ˆì»¤ or ê³„ì‚°) */
  const [chordCues, setChordCues] = useState<ChordCue[]>([])
  const [nowChord, setNowChord] = useState('')
  const [nextChord, setNextChord] = useState('')

  /* í”Œë ˆì´ì–´/íŠ¸ëœìŠ¤í¬íŠ¸ */
  const midiEl = useRef<HTMLAudioElement>(null)
  const bassEl = useRef<HTMLAudioElement>(null)
  const [duration, setDuration] = useState(0)
  const [position, setPosition] = useState(0)
  const [playing, setPlaying] = useState(false)
  const rafRef = useRef<number | null>(null)
  const transportStartAt = useRef<number | null>(null)

  /* ë¯¹ì„œ */
  const [midiVol, setMidiVol] = useState(0.9)
  const [bassVol, setBassVol] = useState(1.0)
  const [playMidi, setPlayMidi] = useState(true)
  const [playBass, setPlayBass] = useState(true)
  const [loop, setLoop] = useState(false)

  /* í•©ì¹˜ê¸° */
  const [mergedUrl, setMergedUrl] = useState<string | null>(null)

  /* UX */
  const COUNTIN_BEATS = navState.preRollBeats ?? 4
  const [bassOnly, setBassOnly] = useState(false)
  const [countInLeft, setCountInLeft] = useState<number | null>(null) // overlay í‘œì‹œìš©

  /* ë² ì´ìŠ¤ íŠ¸ë¦¬ë°(ì¹´ìš´íŠ¸ì¸ ì œê±°) */
  const [bassTrimUrl, setBassTrimUrl] = useState<string | null>(null)
  const [bassBuffer, setBassBuffer] = useState<AudioBuffer | null>(null)
  const beatSec = useMemo(() => 60 / Math.max(40, Math.min(300, tempoBpm)), [tempoBpm])
  const preRollSec = useMemo(() => beatSec * COUNTIN_BEATS, [beatSec, COUNTIN_BEATS])

  /* ===== ë…¹ìŒë³¸ â†’ í”„ë¦¬ë¡¤ë§Œí¼ ìë¥´ê¸° ===== */
  useEffect(() => {
    let revoke: string | null = null
    ;(async () => {
      if (!blobUrl) { setBassTrimUrl(null); setBassBuffer(null); return }
      try {
        const ctx = new (window.AudioContext || (window as any).webkitAudioContext)()
        const arr = await (await fetch(blobUrl)).arrayBuffer()
        const src = await ctx.decodeAudioData(arr.slice(0))
        const startSample = Math.floor(preRollSec * src.sampleRate)
        const out = ctx.createBuffer(src.numberOfChannels, Math.max(0, src.length - startSample), src.sampleRate)
        for (let ch = 0; ch < src.numberOfChannels; ch++) {
          out.getChannelData(ch).set(src.getChannelData(ch).subarray(startSample))
        }
        await ctx.close()
        const wav = audioBufferToWavBlob(out)
        const url = URL.createObjectURL(wav)
        setBassTrimUrl(url); setBassBuffer(out); revoke = url
      } catch {
        setBassTrimUrl(null); setBassBuffer(null)
      }
    })()
    return () => { if (revoke) URL.revokeObjectURL(revoke) }
  }, [blobUrl, preRollSec])

  /* ===== ìœ í‹¸: progressionìœ¼ë¡œ í ê³„ì‚°(fallback) ===== */
  function buildCuesFromProgression(prog: string[], barsPerChord = 1): ChordCue[] {
    const beatsPerBar = timeSig?.[0] ?? 4
    const secPerBar = beatsPerBar * beatSec
    let t = 0
    const cues: ChordCue[] = prog.map((text) => {
      const cue = { text, time: t }
      t += secPerBar * Math.max(1, barsPerChord)
      return cue
    })
    return cues
  }

  /* ===== ìƒì„± íŠ¸ë™ì—ì„œ ìë™ ë¶€íŒ… ===== */
  useEffect(() => {
    async function bootstrapFromGeneratedJob(jobId: string) {
      // 1) MIDI â†’ í ì‹œë„(â€» preRoll ë³´ì •ì„ í•˜ì§€ ì•ŠëŠ”ë‹¤: MIDI ì¬ìƒ 0ì´ˆë¶€í„° ì½”ë“œ ì‹œì‘)
      try {
        const midiArr = await (await fetch(navState.midiUrl ?? midiUrl(jobId))).arrayBuffer()
        const cues = await extractChordCuesFromMidi(midiArr, { preRollSec: 0, windowBeats: 1 })
        if (cues.length) setChordCues(cues)
        // ë©”íƒ€
        const midi = new Midi(midiArr)
        setTempoBpm(navState.tempo ?? (midi.header.tempos?.[0]?.bpm ?? tempoBpm))
        const ts = (midi.header.timeSignatures?.[0]?.timeSignature as number[]) || [4, 4]
        setTimeSig([ts[0] ?? 4, ts[1] ?? 4])
        setMidiTracks(midi.tracks.map(t => ({
          name: t.name || '(no name)',
          channel: t.channel,
          instrument: t.instrument?.name || (t.instrument?.number != null ? `program ${t.instrument.number}` : undefined),
          notes: t.notes.length,
        })))
      } catch {}

      // 2) WAV ì„¸íŒ… + ë””ì½”ë“œ
      const wurl = navState.wavUrl ?? wavUrl(jobId)
      setMidiAudioUrl(wurl)
      const ctx = new (window.AudioContext || (window as any).webkitAudioContext)()
      try {
        const wArr = await (await fetch(wurl)).arrayBuffer()
        setMidiBuffer(await ctx.decodeAudioData(wArr.slice(0)))
      } finally { await ctx.close() }
    }
    if (navState.jobId) bootstrapFromGeneratedJob(navState.jobId).catch(console.error)
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [navState.jobId])

  /* ===== progressionë§Œ ë„˜ì–´ì˜¨ ê²½ìš°ì˜ í ê³„ì‚° ===== */
  const fallbackCues = useMemo(() => {
    if (chordCues.length) return chordCues
    if (navState.progression && navState.progression.length) {
      return buildCuesFromProgression(navState.progression, navState.barsPerChord ?? 1)
    }
    return []
  }, [chordCues, navState.progression, navState.barsPerChord, beatSec, timeSig])

  /* ===== ìˆ˜ë™ MIDI ì—…ë¡œë“œë„ ì§€ì› ===== */
  async function handleMidiFile(file: File) {
    setMidiFile(file)
    setMidiAudioUrl(null); setMidiBuffer(null); setMergedUrl(null)
    setMidiTracks([]); setChordCues([]); setNowChord(''); setNextChord('')
    setRendering(true)
    try {
      const arr = await file.arrayBuffer()
      const midi = new Midi(arr)
      const bpm = midi.header.tempos?.[0]?.bpm ?? 100
      setTempoBpm(bpm)
      const ts = (midi.header.timeSignatures?.[0]?.timeSignature as number[]) || [4, 4]
      setTimeSig([ts[0] ?? 4, ts[1] ?? 4])
      setMidiTracks(midi.tracks.map(t => ({
        name: t.name || '(no name)',
        channel: t.channel,
        instrument: t.instrument?.name || (t.instrument?.number != null ? `program ${t.instrument.number}` : undefined),
        notes: t.notes.length,
      })))

      // ë§ˆì»¤ê°€ ìˆìœ¼ë©´ ì‚¬ìš©(ìˆ˜ë™ ì—…ë¡œë“œëŠ” preRoll ë³´ì • X)
      const cues = await extractChordCuesFromMidi(arr, { preRollSec: 0, windowBeats: 1 })
      setChordCues(cues)

      // ì„œë²„ ë Œë” WAV
      const { wavUrl: wurl } = await renderMidiOnServer(file)
      setMidiAudioUrl(wurl)

      // ë¯¹ì‹±ìš© ë²„í¼
      const ctx = new (window.AudioContext || (window as any).webkitAudioContext)()
      const wavArr = await (await fetch(wurl)).arrayBuffer()
      setMidiBuffer(await ctx.decodeAudioData(wavArr.slice(0)))
      await ctx.close()
    } finally {
      setRendering(false)
    }
  }

  /* ===== ì¹´ìš´íŠ¸ì¸ ===== */
  async function playCountIn(beats: number, bpm: number) {
    setCountInLeft(beats)
    const ctx = new (window.AudioContext || (window as any).webkitAudioContext)()
    const beat = 60 / Math.max(40, Math.min(300, bpm))
    const t0 = ctx.currentTime + 0.05
    for (let i = 0; i < beats; i++) {
      const osc = ctx.createOscillator()
      const g = ctx.createGain()
      osc.type = 'sine'
      osc.frequency.value = i === 0 ? 1200 : 800
      g.gain.value = 0
      osc.connect(g).connect(ctx.destination)
      const ts = t0 + i * beat
      g.gain.setValueAtTime(0, ts)
      g.gain.linearRampToValueAtTime(0.8, ts + 0.01)
      g.gain.exponentialRampToValueAtTime(0.0001, ts + 0.15)
      osc.start(ts); osc.stop(ts + 0.2)
      // ì˜¤ë²„ë ˆì´ ìˆ«ì ì—…ë°ì´íŠ¸
      setTimeout(() => setCountInLeft(beats - i - 1), Math.max(0, (ts - ctx.currentTime) * 1000))
    }
    return new Promise<void>((resolve) => {
      const endAt = t0 + beats * beat
      const ms = Math.ceil((endAt - ctx.currentTime) * 1000) + 20
      setTimeout(() => { ctx.close().finally(() => { setCountInLeft(null); resolve() }) }, ms)
    })
  }

  /* ===== ì˜¤í† í”Œë ˆì´ í•´ì œ ===== */
  async function ensureUnlocked() {
    const el = midiEl.current; if (!el) return
    const prev = el.muted; el.muted = true
    try { await el.play().catch(()=>{}); el.pause() } finally { el.muted = prev }
  }

  /* ===== ë…¹ìŒ ì‹œì‘ ===== */
  async function startRecordingFlow() {
    if (!midiAudioUrl && !bassOnly) { alert('ë¨¼ì € MIDI ë°±í‚¹ì´ ì¤€ë¹„ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. (ë˜ëŠ” â€œë² ì´ìŠ¤ë§Œ ë…¹ìŒâ€ì„ ì¼œì„¸ìš”)'); return }
    if (!recording) await start()
    await ensureUnlocked()
    await playCountIn(COUNTIN_BEATS, tempoBpm)

    transportStartAt.current = performance.now()
    if (!bassOnly && midiEl.current) {
      midiEl.current.currentTime = 0
      midiEl.current.play().catch(()=>{})
    }
    setPlaying(true)
    if (!rafRef.current) tick()
  }

  /* ===== íŠ¸ëœìŠ¤í¬íŠ¸ / HUD ===== */
  function syncVolumesAndMutes() {
    if (midiEl.current) { midiEl.current.volume = midiVol; midiEl.current.muted = !playMidi; midiEl.current.loop = loop }
    if (bassEl.current) { bassEl.current.volume = bassVol; bassEl.current.muted = !playBass; bassEl.current.loop = loop }
  }

  function tick() {
    let t = midiEl.current ? (midiEl.current.currentTime ?? 0) : 0
    if ((!midiEl.current || midiEl.current.paused) && transportStartAt.current) {
      t = (performance.now() - transportStartAt.current) / 1000
    }
    setPosition(t)

    const cues = chordCues.length ? chordCues : fallbackCues
    if (cues.length > 0) {
      const { now, next } = getNowNextChord(cues, t)
      setNowChord(now); setNextChord(next)
    }
    rafRef.current = requestAnimationFrame(tick)
  }

  function play() {
    if (!bassOnly) midiEl.current?.play().catch(()=>{})
    bassEl.current?.play().catch(()=>{})
    setPlaying(true)
    if (!rafRef.current) tick()
  }
  function pause() {
    midiEl.current?.pause()
    bassEl.current?.pause()
    setPlaying(false)
    if (rafRef.current) { cancelAnimationFrame(rafRef.current); rafRef.current = null }
  }
  function stopAll() {
    pause()
    if (midiEl.current) midiEl.current.currentTime = 0
    if (bassEl.current) bassEl.current.currentTime = 0
    transportStartAt.current = null
    setPosition(0)
    setNowChord(''); setNextChord('')
  }
  function seek(sec: number) {
    if (midiEl.current) midiEl.current.currentTime = sec
    if (bassEl.current) bassEl.current.currentTime = sec
    transportStartAt.current = performance.now() - sec * 1000
    setPosition(sec)
  }

  // duration/ended
  useEffect(() => {
    function updateDur() {
      const d1 = midiEl.current?.duration ?? 0
      const d2 = bassEl.current?.duration ?? 0
      const d = Math.max(isFinite(d1) ? d1 : 0, isFinite(d2) ? d2 : 0)
      if (d && isFinite(d)) setDuration(d)
    }
    const a = midiEl.current; const b = bassEl.current
    a?.addEventListener('loadedmetadata', updateDur)
    b?.addEventListener('loadedmetadata', updateDur)
    a?.addEventListener('ended', () => !loop && pause())
    b?.addEventListener('ended', () => !loop && pause())
    updateDur()
    return () => {
      a?.removeEventListener('loadedmetadata', updateDur)
      b?.removeEventListener('loadedmetadata', updateDur)
    }
  }, [midiAudioUrl, bassTrimUrl, loop])

  // ë„¤ì´í‹°ë¸Œ ì»¨íŠ¸ë¡¤ë„ HUD ë™ê¸°
  useEffect(() => {
    const a = midiEl.current; const b = bassEl.current
    if (!a && !b) return
    const onTU = () => {
      const t = Math.max(a?.currentTime ?? 0, b?.currentTime ?? 0)
      setPosition(t)
      const cues = chordCues.length ? chordCues : fallbackCues
      if (cues.length) {
        const { now, next } = getNowNextChord(cues, t)
        setNowChord(now); setNextChord(next)
      }
    }
    const onPlay = () => {
      setPlaying(true)
      if (!rafRef.current) {
        rafRef.current = requestAnimationFrame(function loop() {
          onTU(); rafRef.current = requestAnimationFrame(loop)
        })
      }
    }
    const onPauseOrEnd = () => {
      setPlaying(false)
      if (rafRef.current) { cancelAnimationFrame(rafRef.current); rafRef.current = null }
      onTU()
    }
    ;[a,b].forEach(el => {
      el?.addEventListener('play', onPlay)
      el?.addEventListener('pause', onPauseOrEnd)
      el?.addEventListener('ended', onPauseOrEnd)
      el?.addEventListener('timeupdate', onTU)
      el?.addEventListener('seeking', onTU)
      el?.addEventListener('seeked', onTU)
    })
    onTU()
    return () => {
      ;[a,b].forEach(el => {
        el?.removeEventListener('play', onPlay)
        el?.removeEventListener('pause', onPauseOrEnd)
        el?.removeEventListener('ended', onPauseOrEnd)
        el?.removeEventListener('timeupdate', onTU)
        el?.removeEventListener('seeking', onTU)
        el?.removeEventListener('seeked', onTU)
      })
      if (rafRef.current) { cancelAnimationFrame(rafRef.current); rafRef.current = null }
    }
  }, [midiAudioUrl, bassTrimUrl, blobUrl, chordCues, fallbackCues])

  useEffect(() => () => { if (rafRef.current) cancelAnimationFrame(rafRef.current) }, [])

  /* í‚¤ë³´ë“œ ë‹¨ì¶•í‚¤ */
  useEffect(() => {
    const onKey = (e: KeyboardEvent) => {
      if (e.code === 'Space') { e.preventDefault(); playing ? pause() : play() }
      if (e.key.toLowerCase() === 'r') { e.preventDefault(); startRecordingFlow().catch(console.error) }
    }
    window.addEventListener('keydown', onKey)
    return () => window.removeEventListener('keydown', onKey)
  }, [playing, tempoBpm, midiAudioUrl, bassOnly, startRecordingFlow])

  /* ===== í•©ì¹˜ê¸° ===== */
  async function mergeAndExport() {
    if (!midiBuffer) return
    if (mergedUrl) URL.revokeObjectURL(mergedUrl)
    setMergedUrl(null)

    let bass: AudioBuffer | null = bassBuffer
    if (!bass && blobUrl) {
      const ctx = new (window.AudioContext || (window as any).webkitAudioContext)()
      const arr = await (await fetch(blobUrl)).arrayBuffer()
      const src = await ctx.decodeAudioData(arr.slice(0))
      const startSample = Math.floor(preRollSec * src.sampleRate)
      const out = ctx.createBuffer(src.numberOfChannels, Math.max(0, src.length - startSample), src.sampleRate)
      for (let ch = 0; ch < src.numberOfChannels; ch++) {
        out.getChannelData(ch).set(src.getChannelData(ch).subarray(startSample))
      }
      await ctx.close()
      bass = out
    }
    if (!bass) return

    const mixed = await mixBuffersToAudioBuffer(midiBuffer, bass, { sampleRate: 48000, fadeOutSec: 0.03 })
    const wav = audioBufferToWavBlob(mixed)
    const url = URL.createObjectURL(wav)
    setMergedUrl(url)
  }
  useEffect(() => () => { if (mergedUrl) URL.revokeObjectURL(mergedUrl) }, [mergedUrl])

  /* ===== íŒŒìƒ UI ë°ì´í„° ===== */
  const cuesForUI = chordCues.length ? chordCues : fallbackCues
  const totalFromCues = useMemo(() => {
    if (!cuesForUI.length) return 0
    const last = cuesForUI[cuesForUI.length - 1]
    const barsPerChord = navState.barsPerChord ?? 1
    const tail = (timeSig?.[0] ?? 4) * beatSec * Math.max(1, barsPerChord)
    return last.time + tail
  }, [cuesForUI, beatSec, timeSig, navState.barsPerChord])

  /* ===== ë Œë” ===== */
  return (
    <div className="pmx-wrap">

      {/* Step ì•ˆë‚´ & HUD */}
      <section className="pmx-panel">
        <div className="top-steps">
          <div className="step"><span>1</span> ì¥ì¹˜ë¥¼ ì„ íƒí•˜ê³  ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•˜ì„¸ìš”.</div>
          <div className="step"><span>2</span> {bassOnly ? 'ë² ì´ìŠ¤ë§Œ' : 'ë°±í‚¹ê³¼ í•¨ê»˜'} <b>ì¬ìƒ/ë…¹ìŒ</b>í•˜ì„¸ìš”. (R: ë…¹ìŒ / Space: ì¬ìƒ)</div>
          <div className="step"><span>3</span> ìƒë‹¨ HUDì—ì„œ <b>í˜„ì¬/ë‹¤ìŒ ì½”ë“œ</b>ë¥¼ í™•ì¸í•˜ì„¸ìš”.</div>
          <div className="step"><span>4</span> ëë‚˜ë©´ <b>í•©ì¹˜ê¸°</b>ë¡œ WAVë¥¼ ë°›ìœ¼ì„¸ìš”.</div>
        </div>

        <div className="hud">
          <div className="ring">
            <div className="now">{nowChord || 'Ready'}</div>
            <div className="next">{nextChord ? `Next â€¢ ${nextChord}` : ' '}</div>
          </div>

          {/* ì¹´ìš´íŠ¸ì¸ ì˜¤ë²„ë ˆì´ */}
          {countInLeft !== null && (
            <div className="countin">
              <div className="num">{countInLeft === 0 ? 'GO!' : countInLeft}</div>
              <div className="sub">ì¹´ìš´íŠ¸ì¸ {COUNTIN_BEATS}ë°•</div>
            </div>
          )}
        </div>
      </section>

      {/* ì…ë ¥ ì¥ì¹˜ */}
      <section className="pmx-panel">
        <h3>ğŸ› ì…ë ¥ ì¥ì¹˜</h3>
        <div className="row">
          <DeviceSelect value={deviceId} onChange={setDeviceId} />
          <button className="btn" onClick={async ()=>{ await navigator.mediaDevices.getUserMedia({ audio: true }) }}>
            ğŸ¤ ë§ˆì´í¬ ê¶Œí•œ
          </button>
          <button className="btn" onClick={() => window.location.reload()}>ğŸ”„ ìƒˆë¡œê³ ì¹¨</button>
        </div>
        {recErr && <div className="warn">ë…¹ìŒ ì˜¤ë¥˜: {recErr}</div>}
      </section>

      {/* íƒ€ì„ë¼ì¸ (ì½”ë“œ ë¼ì¸) */}
      {cuesForUI.length > 0 && (
        <section className="pmx-panel">
          <h3>ğŸ§­ ì½”ë“œ íƒ€ì„ë¼ì¸</h3>
          <div className="timeline">
            {cuesForUI.map((c, i) => {
              const t0 = c.time
              const t1 = cuesForUI[i+1]?.time ?? totalFromCues
              const w = Math.max(4, (t1 - t0) / Math.max(1, totalFromCues) * 100)
              const active = position >= t0 && position < t1
              return (
                <div key={i} className={`cell ${active ? 'active' : ''}`} style={{ width: `${w}%` }}>
                  <span>{c.text}</span>
                </div>
              )
            })}
            <div className="playhead" style={{ left: `${Math.min(100, position / Math.max(0.001, totalFromCues) * 100)}%` }} />
          </div>
        </section>
      )}

      {/* MIDI íŒŒì¼ / ë¯¸ë¦¬ë“£ê¸° */}
      <section className="pmx-panel">
        <h3>ğŸ¼ ë°±í‚¹(ë¯¸ë”” ë Œë”)</h3>
        <div className="thin" style={{marginBottom:8}}>
          {midiAudioUrl ? 'ê²°ê³¼ì—ì„œ ì „ë‹¬ëœ ë°±í‚¹ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.' : 'í•„ìš”í•˜ë‹¤ë©´ MIDI íŒŒì¼ì„ ì§ì ‘ ì„ íƒí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.'}
        </div>

        <div className="row">
          <label className="file">
            <input type="file" accept=".mid,.midi" onChange={e => {
              const f = e.target.files?.[0]; if (f) handleMidiFile(f)
            }}/>
            <span>íŒŒì¼ ì„ íƒ</span>
          </label>
          {midiFile && <span className="hint">{midiFile.name}</span>}
          {rendering && <span className="hint">ì„œë²„ ë Œë”ë§ ì¤‘â€¦</span>}
        </div>

        <div className="preview" style={{marginTop:8}}>
          {midiAudioUrl
            ? <audio ref={midiEl} src={midiAudioUrl} preload="metadata" controls
                     onLoadedMetadata={syncVolumesAndMutes}
                     onPlay={syncVolumesAndMutes}
                     onError={(e)=>console.warn('MIDI audio error', e)} />
            : <div className="thin">ê²°ê³¼ ì¹´ë“œì—ì„œ â€œë² ì´ìŠ¤ ë…¹ìŒí•˜ê¸°â€ë¡œ ë“¤ì–´ì˜¤ë©´ ìë™ìœ¼ë¡œ ì±„ì›Œì§‘ë‹ˆë‹¤.</div>}
        </div>

        {(midiTracks.length > 0) && (
          <details className="tracks" style={{marginTop:8}}>
            <summary>íŠ¸ë™ ë©”íƒ€ ë³´ê¸°</summary>
            <div className="thin" style={{margin:'6px 0'}}>Tempo: {tempoBpm} BPM â€¢ Time Sig: {timeSig[0]}/{timeSig[1]}</div>
            <ul>
              {midiTracks.map((t, i) => (
                <li key={i}>
                  <strong>{t.name}</strong>
                  <span className="thin"> ({t.instrument ?? 'inst'}, ch {t.channel ?? '-'})</span>
                  <span className="thin"> â€¢ notes: {t.notes}</span>
                </li>
              ))}
            </ul>
          </details>
        )}
      </section>

      {/* ë² ì´ìŠ¤ ë…¹ìŒ */}
      <section className="pmx-panel">
        <h3>ğŸ™ ë² ì´ìŠ¤ ë…¹ìŒ</h3>
        <div className="row" style={{gap:12, alignItems:'center'}}>
          {!recording
            ? <button className="btn primary" onClick={startRecordingFlow}>â— ë…¹ìŒ ì‹œì‘ (ì¹´ìš´íŠ¸ì¸ {COUNTIN_BEATS}ë°•)</button>
            : <button className="btn danger" onClick={stop}>â–  ì •ì§€</button>}
          <label className="row" style={{gap:6}}>
            <input type="checkbox" checked={bassOnly} onChange={e=>setBassOnly(e.target.checked)} />
            ë² ì´ìŠ¤ë§Œ ë…¹ìŒ(ë°±í‚¹ ë¯¸ì¬ìƒ)
          </label>
        </div>
      </section>

      {/* Bass ë¯¸ë¦¬ë“£ê¸° & ë¯¹ì„œ */}
      <section className="pmx-panel">
        <h3>ğŸš ë¯¸ë¦¬ë“£ê¸° & íŠ¸ëœìŠ¤í¬íŠ¸</h3>
        <div className="mixer">
          <div className="ch">
            <div className="ch-title">Bass</div>
            <div className="row">
              <label className="row"><input type="checkbox" checked={playBass} onChange={e=>setPlayBass(e.target.checked)} /> ì¬ìƒ</label>
            </div>
            <div className="col">
              <input type="range" min={0} max={1} step={0.01} value={bassVol} onChange={e=>setBassVol(Number(e.target.value))}/>
              <div className="hint">ë³¼ë¥¨ {Math.round(bassVol*100)}%</div>
            </div>
            <div className="preview">
              {(bassTrimUrl || blobUrl)
                ? <audio ref={bassEl} src={(bassTrimUrl ?? blobUrl)!} preload="metadata" controls
                         onLoadedMetadata={syncVolumesAndMutes}
                         onPlay={syncVolumesAndMutes}
                         onError={(e)=>console.warn('Bass audio error', e)} />
                : <div className="thin">ë…¹ìŒ í›„ ì¬ìƒ ê°€ëŠ¥</div>}
              {bassTrimUrl && <div className="tiny" style={{marginTop:4}}>â€» ì¹´ìš´íŠ¸ì¸ {COUNTIN_BEATS}ë°• êµ¬ê°„ì„ ìë™ ì œê±°í–ˆìŠµë‹ˆë‹¤.</div>}
            </div>
          </div>
        </div>

        {/* ë‹¨ì¼ íŠ¸ëœìŠ¤í¬íŠ¸ */}
        <div className="transport" style={{marginTop:12}}>
          <button className="btn" onClick={playing ? pause : play} disabled={!midiAudioUrl && !bassTrimUrl && !blobUrl}>
            {playing ? 'â¸ ì¼ì‹œì •ì§€ (Space)' : 'â–¶ï¸ ì¬ìƒ (Space)'}
          </button>
          <button className="btn" onClick={stopAll}>â¹ ì •ì§€</button>
          <label className="row" style={{gap:8}}>
            <input
              aria-label="seek"
              type="range" min={0} max={Math.max(duration || totalFromCues, 0.001)} step={0.01}
              value={position} onChange={e => seek(Number(e.target.value))}
              style={{width:360}}
            />
            <span className="hint">{formatTime(position)} / {formatTime(Math.max(duration, totalFromCues))}</span>
          </label>
          <label className="row" style={{gap:6}}>
            <input type="checkbox" checked={loop} onChange={e=>setLoop(e.target.checked)} />
            <span className="hint">ë£¨í”„</span>
          </label>
        </div>
      </section>

      {/* í•©ì¹˜ê¸° & ë‹¤ìš´ë¡œë“œ */}
      <section className="pmx-panel">
        <h3>â¬‡ï¸ í•©ì¹˜ê¸° & ë‹¤ìš´ë¡œë“œ</h3>
        <button className="btn" onClick={mergeAndExport} disabled={!midiBuffer || (!bassBuffer && !blobUrl)}>
          ìŒì› í•©ì¹˜ê¸° (WAV ìƒì„±)
        </button>
        {mergedUrl && (
          <div className="result">
            <audio src={mergedUrl} controls />
            <div><a className="btn" href={mergedUrl} download={makeDownloadName(midiFile?.name)}>â¬‡ í•©ì¹œ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (WAV)</a></div>
          </div>
        )}
        <div className="tiny">* .midì—ëŠ” ì˜¤ë””ì˜¤ê°€ ì—†ìœ¼ë¯€ë¡œ í•©ì¹œ ê²°ê³¼ëŠ” WAVë¡œ ì œê³µí•©ë‹ˆë‹¤.</div>
      </section>
    </div>
  )
}

/* ===== ìœ í‹¸ ===== */
function makeDownloadName(midiName?: string) {
  const base = midiName?.replace(/\.(mid|midi)$/i, '') || 'result'
  return `${base}_with_bass.wav`
}
function formatTime(sec: number) {
  if (!isFinite(sec)) return '0:00'
  const m = Math.floor(sec / 60)
  const s = Math.floor(sec % 60).toString().padStart(2, '0')
  return `${m}:${s}`
}