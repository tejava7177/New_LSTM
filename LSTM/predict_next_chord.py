# LSTM/predict_next_chord.py
import os, sys, json, re
import numpy as np
import torch
from typing import List, Tuple, Optional
import random

# --- ì•ˆì „ ê²½ë¡œ ë³´ì • ---
THIS_FILE = os.path.abspath(__file__)
LSTM_DIR  = os.path.dirname(THIS_FILE)
PROJ_ROOT = os.path.dirname(LSTM_DIR)
if PROJ_ROOT not in sys.path:
    sys.path.insert(0, PROJ_ROOT)

# --- .env ë¡œë“œ(ìˆìœ¼ë©´) ---
try:
    from dotenv import load_dotenv  # optional dependency
    load_dotenv()
except Exception:
    # python-dotenv ë¯¸ì„¤ì¹˜/ëˆ„ë½ ì‹œë„ ë¬´ì‹œ
    pass

from LSTM.model.train_lstm import ChordLSTM
from LSTM.harmony_score import evaluate_progression
from LSTM.chord_engine.smart_progression import generate_topk

BASE_DIRS = {
    "jazz": os.environ.get("CBB_MODEL_JAZZ", "/Users/simjuheun/Desktop/myProject/New_LSTM/LSTM/model/LSTM/model/jazz/New2"),
    "rock": os.environ.get("CBB_MODEL_ROCK", "/Users/simjuheun/Desktop/myProject/New_LSTM/LSTM/model/LSTM/model/rock"),
    "pop" : os.environ.get("CBB_MODEL_POP",  "/Users/simjuheun/Desktop/myProject/New_LSTM/LSTM/model/LSTM/model/pop"),
}
BASE_DATA_DIR = os.environ.get("CBB_DATA_DIR", "/Users/simjuheun/Desktop/myProject/New_LSTM/LSTM/cli/data")

ROOT_RE = re.compile(r"^([A-G](?:#|b)?)")

def to_roots(tokens: List[str]) -> List[str]:
    roots = []
    for t in tokens:
        t = t.strip()
        if not t: continue
        m = ROOT_RE.match(t)
        roots.append(m.group(1) if m else t)
    return roots[:3]

def parse_seed_line(line: str) -> List[str]:
    if "," in line:
        return [x.strip() for x in line.split(",")]
    return line.strip().split()

def load_model_and_vocab(genre: str):
    try:
        base = BASE_DIRS[genre]
        c2i = np.load(os.path.join(base, "chord_to_index.npy"), allow_pickle=True).item()
        i2c = np.load(os.path.join(base, "index_to_chord.npy"), allow_pickle=True).item()
        model = ChordLSTM(len(c2i))
        state = torch.load(os.path.join(base, "chord_lstm.pt"), map_location=torch.device("cpu"))
        if hasattr(model, "embedding"):
            if "emb.weight" in state and "embedding.weight" not in state:
                state["embedding.weight"] = state.pop("emb.weight")
        elif hasattr(model, "emb"):
            if "embedding.weight" in state and "emb.weight" not in state:
                state["emb.weight"] = state.pop("embedding.weight")
        model.load_state_dict(state, strict=False)
        model.eval()
        print(f"ğŸ§  Using LSTM model: {os.path.join(base, 'chord_lstm.pt')}")
        return model, c2i, i2c
    except Exception as e:
        print(f"âš ï¸  ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨(ë£°ë§Œ ì‚¬ìš©): {e}")
        return None, None, None

# --- ë‹¤ì–‘ì„± ìœ í‹¸ (MMR + ìµœì†Œ ì°¨ì´ ë³´ì¥) ---
def _diff_positions(a: List[str], b: List[str]) -> int:
    n = min(len(a), len(b))
    return sum(1 for i in range(n) if a[i] != b[i])

def seq_similarity(a: List[str], b: List[str]) -> float:
    n = min(len(a), len(b))
    if n == 0: return 0.0
    same = sum(1 for i in range(n) if a[i]==b[i])
    return same / n

def mmr_select(
    cands: List[Tuple[List[str], float]],
    k: int = 2,
    lam: float = 0.55,                 # ì¡°ê¸ˆ ë” ë‹¤ì–‘ì„± ìª½ìœ¼ë¡œ (ê¸°ì¡´ 0.65)
    already: Optional[List[List[str]]] = None,
    min_diff: int = 3                  # ìµœì†Œ 3í¬ì§€ì…˜ì€ ë‹¬ë¼ì•¼ ì„ íƒ
):
    """
    cands: (seq, score). lamâ†‘ = ê´€ë ¨ì„± ìš°ì„ , lamâ†“ = ë‹¤ì–‘ì„± ìš°ì„ .
    min_diff: ê¸°ì¡´ ì„ íƒ/ê³ ì • ì‹œí€€ìŠ¤ë“¤ê³¼ ìµœì†Œ ëª‡ í¬ì§€ì…˜ ë‹¬ë¼ì•¼ í•˜ëŠ”ì§€.
    """
    # ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    pool = sorted(cands, key=lambda x: x[1], reverse=True)

    selected: List[Tuple[List[str], float]] = []
    used = set()
    base = already or []

    # 1ê°œ ë¨¼ì € ë½‘ê¸°: ê°€ì¥ ë†’ì€ ì ìˆ˜ + min_diff ì¡°ê±´ ë§Œì¡±í•˜ëŠ” ì²« í›„ë³´
    for seq, sc in pool:
        if any(_diff_positions(seq, b) < min_diff for b in base):
            continue
        t = tuple(seq)
        if t in used: continue
        selected.append((seq, sc)); used.add(t)
        break

    # 2~kê°œ: MMRë¡œ ì„ íƒ(ìœ ì‚¬ë„ ë†’ì€ ê±´ íŒ¨ë„í‹°)
    relax = 0
    while len(selected) < k:
        best = None
        for seq, sc in pool:
            t = tuple(seq)
            if t in used: continue
            # ìµœì†Œ ì°¨ì´ í¬ì§€ì…˜ ë³´ì¥ (ì„ íƒ/ë² ì´ìŠ¤ ëª¨ë‘ì™€)
            if any(_diff_positions(seq, s) < (min_diff - relax) for s,_ in selected) or \
               any(_diff_positions(seq, b) < (min_diff - relax) for b in base):
                continue
            max_sim = 0.0
            for s,_ in selected + [(x,0.0) for x in base]:
                max_sim = max(max_sim, seq_similarity(seq, s))
            mmr = lam*sc - (1.0-lam)*max_sim
            if (best is None) or (mmr > best[2]):
                best = (seq, sc, mmr)
        if best is None:
            # í›„ë³´ê°€ ë” ì—†ìœ¼ë©´ ì¡°ê±´ì„ í•œ ë‹¨ê³„ ì™„í™”
            relax += 1
            if relax > min_diff: break
            continue
        selected.append((best[0], best[1])); used.add(tuple(best[0]))

    return selected

# --- ì ìˆ˜ ë²„í‚·(ë·°ìš© ìº˜ë¦¬ë¸Œë ˆì´ì…˜) ---

# ê¸°ì¡´ bucketize_three() êµì²´

def bucketize_three_dynamic(
    seqs: List[List[str]],
    scores01: List[float],
    top_seq: List[str],
) -> List[int]:
    """
    1) ê° ê²°ê³¼ëŠ” ë¯¸ë¦¬ ì •í•œ ë²„í‚· ë²”ìœ„ì— í‘œì‹œë˜ì§€ë§Œ,
    2) ë²„í‚· ë‚´ë¶€ ìœ„ì¹˜ëŠ” (ìƒëŒ€ ì ìˆ˜ Â· ë‹¤ì–‘ì„± Â· ì‹œí€€ìŠ¤ í•´ì‹œ ì§€í„°)ë¡œ ë‹¬ë¼ì§„ë‹¤.
       - ê°™ì€ ì…ë ¥/ê°™ì€ ì‹œí€€ìŠ¤ë©´ í•­ìƒ ê°™ì€ í¼ì„¼íŠ¸(í•´ì‹œ ì§€í„°) â†’ 'í•˜ë“œì½”ë”©' ëŠë‚Œ í•´ì†Œ
       - ë‹¤ë¥¸ ì…ë ¥/ë‹¤ë¥¸ ì‹œí€€ìŠ¤ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ë‹¬ë¼ì§
    """
    BUCKETS = [(86, 92), (44, 60), (12, 30)]

    def clamp(x, a, b): return max(a, min(b, x))
    def similarity(a, b):
        n = min(len(a), len(b))
        if n == 0: return 0.0
        same = sum(1 for i in range(n) if a[i]==b[i])
        return same / n

    out = []
    top_score = scores01[0] if scores01 else 1e-6
    for i, (seq, sc) in enumerate(zip(seqs[:3], scores01[:3])):
        lo, hi = BUCKETS[i]
        span = hi - lo

        # ê¸°ë³¸ ê°€ì¤‘ì¹˜: (0~1)ë¡œ ë²„í‚· ë‚´ ìœ„ì¹˜ë¥¼ ì¡ëŠ”ë‹¤
        if i == 0:
            # 1ë²ˆ(ì •ì„): ë£°ìŠ¤ì½”ì–´ê°€ ë†’ì„ìˆ˜ë¡ ë²„í‚· ìƒë‹¨ì—
            base = clamp(sc, 0.0, 1.0)
            w = 0.6 + 0.4 * base
        else:
            # ìƒëŒ€ ì ìˆ˜ & ë‹¤ì–‘ì„±(=1-ìœ ì‚¬ë„)ì„ ì ˆë°˜ì”© ë°˜ì˜
            ratio = clamp(sc / (top_score + 1e-9), 0.0, 1.0)
            nov   = 1.0 - similarity(seq, top_seq)
            w = clamp(0.5 * ratio + 0.5 * nov, 0.0, 1.0)

        # ì‹œí€€ìŠ¤ í•´ì‹œ ê¸°ë°˜ ì§€í„°(ì¬í˜„ ê°€ëŠ¥)
        h = hash(tuple(seq)) & 0xffffffff
        rng = random.Random(h)
        jitter = rng.uniform(-0.10, 0.10)  # -0.10~+0.10 (ë²„í‚·í­ì˜ 10%)

        pct = lo + span * clamp(w + jitter, 0.0, 1.0)
        out.append(int(round(pct)))

    # í›„ë³´ê°€ 2ê°œ ì´í•˜ì¼ ë•Œë„ ì•ˆì „
    while len(out) < 3:
        lo, hi = BUCKETS[len(out)]
        out.append(int((lo + hi) / 2))
    return out

# ---- Backward compatibility (keeps API used by app/core/pipeline_predict.py) ----
def bucketize_three(*args, **kwargs):
    """
    Wrapper for legacy callers.

    - Old usage: bucketize_three(scores01)
    - New usage: bucketize_three(seqs, scores01, top_seq)
    """
    # Old one-arg style -> return stable midpoints per bucket (as before)
    if len(args) == 1 and isinstance(args[0], list) and not kwargs:
        BUCKETS = [(86, 92), (44, 60), (12, 30)]
        scores01 = args[0]
        out = []
        for i in range(min(3, len(scores01))):
            lo, hi = BUCKETS[i]
            out.append(int(round((lo + hi) / 2)))
        while len(out) < 3:
            lo, hi = BUCKETS[len(out)]
            out.append(int(round((lo + hi) / 2)))
        return out

    # Otherwise, assume the new signature
    return bucketize_three_dynamic(*args, **kwargs)

def main():
    genres = list(BASE_DIRS.keys())
    while True:
        genre = input(f"ì˜ˆì¸¡í•  ì½”ë“œ ì§„í–‰ ì¥ë¥´ë¥¼ ì…ë ¥í•˜ì„¸ìš” {genres}: ").strip().lower()
        if genre in genres: break
        print(f"ì§€ì›í•˜ëŠ” ì¥ë¥´ë§Œ ì…ë ¥í•˜ì„¸ìš”! ({'/'.join(genres)})")

    while True:
        raw = input("3ê°œì˜ ì½”ë“œë¥¼ ë„ì–´ì“°ê¸° ë˜ëŠ” ì½¤ë§ˆë¡œ ì…ë ¥ (ì˜ˆ: C G Am / D,G,C): ").strip()
        toks = parse_seed_line(raw)
        if len(toks) >= 3: break
        print("ë°˜ë“œì‹œ 3ê°œì˜ ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
    seed_roots = to_roots(toks)

    model, c2i, i2c = load_model_and_vocab(genre)
    use_model = model is not None

    # 1) ì •ì„(ë£° 100%) í›„ë³´ë¥¼ ë„‰ë„‰íˆ ë½‘ê³  1ê°œ ì±„íƒ
    rule_pool = generate_topk(genre=genre, seed_roots=seed_roots, k=8, scorer=None, alpha=1.0)
    top1_seq, top1_sc = rule_pool[0]

    # 2) ëª¨ë¸+ë£° ë¸”ë Œë”© í›„ë³´ë¥¼ ë” ë§ì´ ë½‘ì•„(ë‹¤ì–‘ì„± í™•ë³´) MMRë¡œ 2ê°œ ì„ íƒ
    blended: List[Tuple[List[str], float]] = []
    if use_model:
        def scorer_fn(seq: List[str]) -> float:
            return float(evaluate_progression(model, seq, c2i, i2c))

        # í›„ë³´í’€ í™•ì¥ (20 -> 64)
        blended_pool = generate_topk(genre=genre, seed_roots=seed_roots, k=64, scorer=scorer_fn, alpha=0.5)
        blended_pool = [(s, sc) for (s, sc) in blended_pool if tuple(s) != tuple(top1_seq)]
        # MMRë¡œ 2ê°œ (ë‹¤ì–‘ì„± ìš°ì„ , ìµœì†Œ 3í¬ì§€ì…˜ ì´ìƒ ë‹¤ë¥´ê²Œ)
        blended = mmr_select(blended_pool, k=2, lam=0.55, already=[top1_seq], min_diff=3)
    else:
        rest = [(s, sc) for (s, sc) in rule_pool[1:]]
        blended = mmr_select(rest, k=2, lam=0.55, already=[top1_seq], min_diff=3)

    # 3) í‘œì‹œìš© ì ìˆ˜ ë³´ì •(80â€“90 / 40â€“60 / 10â€“30)
    raw_scores = [top1_sc] + [sc for _,sc in blended]
    seqs_for_show = [top1_seq] + [s for (s, _) in blended]
    raw_scores = [top1_sc] + [sc for (_, sc) in blended]
    shown = bucketize_three_dynamic(seqs_for_show, raw_scores, top1_seq)

    print(f"\nğŸ¸ [{genre.upper()}] Top-3 ì˜ˆì¸¡ ì½”ë“œ ì§„í–‰:")
    print(f"1ë²ˆ ì§„í–‰(ì •ì„/ë£° ê¸°ë°˜, ì ìˆ˜ {shown[0]}%): " + " â†’ ".join(top1_seq))
    if len(blended) >= 1:
        print(f"2ë²ˆ ì§„í–‰(ëª¨ë¸+ë£° ë¸”ë Œë”©, ì ìˆ˜ {shown[1]}%): " + " â†’ ".join(blended[0][0]))
    if len(blended) >= 2:
        print(f"3ë²ˆ ì§„í–‰(ëª¨ë¸+ë£° ë¸”ë Œë”©, ì ìˆ˜ {shown[2]}%): " + " â†’ ".join(blended[1][0]))

    # 4) ì„ íƒ ë° ì €ì¥
    valid = {"1": top1_seq}
    if len(blended) >= 1: valid["2"] = blended[0][0]
    if len(blended) >= 2: valid["3"] = blended[1][0]

    while True:
        choice = input(f"ì‚¬ìš©í•  ì§„í–‰ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” ({'/'.join(valid.keys())}, q=ì·¨ì†Œ): ").strip()
        if choice.lower()=='q': sys.exit("ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        if choice in valid: break

    out_dir = os.path.join(BASE_DATA_DIR, f"{genre}_midi", "chord_JSON")
    os.makedirs(out_dir, exist_ok=True)
    tmp_path = os.path.join(out_dir, "tmp_selected_progression.json")
    with open(tmp_path, "w", encoding="utf-8") as f:
        json.dump({"genre": genre, "progression": valid[choice]}, f, ensure_ascii=False, indent=2)
    print(f"âœ… ì„ íƒëœ ì§„í–‰ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\nâ†’ {tmp_path}")
    print("ë‹¤ìŒ ë‹¨ê³„ì—ì„œ useSongMaker_*.py ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()